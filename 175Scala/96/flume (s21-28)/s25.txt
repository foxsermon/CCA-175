Problem Scenario 25 : You have been given below comma separated employee information. That needs to be added in /home/cloudera/flumetest/in.txt file (to do tail source) 
sex,name,city 
1,alok,mumbai 
1,jatin,chennai 
1,yogesh,kolkata 
2,ragini,delhi 
2,jyotsana,pune 
1,valmiki,banglore 


/home/paslechoix/flumetest/in.txt
sex,name,city 
1,alok,mumbai 
1,jatin,chennai 
1,yogesh,kolkata 
2,ragini,delhi 
2,jyotsana,pune 
1,valmiki,banglore 



Create a flume conf file using fastest non-durable channel, which write data in hive warehouse directory, in two separate tables called flumemaleemployee1 and flumefemaleemployee1 
(Create hive table as well for given data). Please use tail source with /home/paslechoix/flumetest/in.txt file. 
flumemaleemployee1 : will contain only male employees data 
flumetemaleemployee1 : Will contain only woman employees data
===================================================================== 
Solution : 
Step 1 : Create hive table tor flumemaleemployee1 
CREATE TABLE flumemaleemployee1
(
Sex_type int, 
name string, 
city string 
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','; 

CREATE TABLE flumefemaleemployee1
(
Sex_type int, 
name string,
city string
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','; 

hive (default)> CREATE TABLE flumemaleemployee1
              > (
              > Sex_type int,
              > name string,
              > city string
              > )
              > ROW FORMAT DELIMITED
              > FIELDS TERMINATED BY ',';
OK
Time taken: 3.366 seconds
hive (default)> CREATE TABLE flumefemaleemployee1
              > (
              > Sex_type int,
              > name string,
              > city string
              > )
              > ROW FORMAT DELIMITED
              > FIELDS TERMINATED BY ',';
OK
Time taken: 0.423 seconds
hive (default)>

Step 2 : Create below directory and file 

mkdir /home/paslechoix/flumetest/ 
cd /home/paslechoix/flumetest/ 

Step 3 : Create flume configuration file, with below configuration for source, sink and channel and save it in flume25.conf.  


agent.sources = tailsrc 
agent.channels = mem1 mem2 
agent.sinks = std1 std2 
agent.sources.tailsrc.type = exec 
agent.sources.tailsrc.command = tail -F /home/paslechoix/flumetest/in.txt 
agent.sources.tailsrc.batchSize = 1 
agent.sources.tailsrc.interceptors = i1 
agent.sources.tailsrc.interceptors.i1.type = regex_extractor 
agent.sources.tailsrc.interceptors.il.regex = ^(\\d) 
agent.sources.tailsrc.interceptors.il.serializers = t1
agent.sources.tailsrc.interceptors.il.serializers.t1 .name = type 
agent.sources.tailsrc.selector.type = multiplexing
agent.sources.tailsrc.selector.header = type 
agent.sources.tailsrc.selector.mapping.l = mem1
agent.sources.tailsrc.selector.mapping.2 = mem2 

agent.sinks.std1.type = hdfs 
agent.sinks.std1.batchSize = 1 
agent.sinks.std1.hdfs.path = /user/hive/warehouse/flumemaleemployee1
agent.sinks.std1.rolllnterval = 0 
agent.sinks.std1.hdfs.fileType = DataStream 

agent.sinks.std2.type = hdfs 
agent.sinks.std2.batchSize = 1 
agent.sinks.std2.hdfs.path = /user/hive/warehouse/flumetemaleemployee1
agent.sinks.std2.rolllnterval = 0 
agent.sinks.std2.hdfs.fileType = DataStream 

agent.channels.mem1.type = memory 
agent.channels.mem1.capacity = 100 
agent.channels.mem2.type = memory 
agent.channels.mem2.capacity = 100 

agent.sources.tailsrc.channels = mem1 mem2 
agent.sinks.std1.channel = mem1
agent.sinks.std2.channel = mem2 

Step 4 : Run below command which will use this configuration file and append data in hdfs. 
Start flume service : 
flume-ng agent --conf /home/paslechoix/flume --conf-file /home/paslechoix/flume/flume25.conf --name agent 
Step 5 : Open another terminal create a file at /home/paslechoix/flumetest/in.txt . 
Step 6 : Enter below data in tile and save it. 
1,alok,mumbai 
1,jatin,chennai 
1,yogesh,kolkata 
2,ragini,delhi 
2,jyotsana,pune 
1,valmiki,banglore 


problem:
1. the agent is started, however, no any output/response to the change in /home/paslechoix/flumetest/in.txt, and no data is received in hive two tables;

Log:

18/02/04 09:11:13 WARN conf.FlumeConfiguration: Agent configuration for 'agent' has no sources.
18/02/04 09:11:13 INFO conf.FlumeConfiguration: Post-validation flume configuration contains configuration for agents: [agent]
18/02/04 09:11:13 INFO node.AbstractConfigurationProvider: Creating channels
18/02/04 09:11:13 INFO channel.DefaultChannelFactory: Creating instance of channel mem2 type memory
18/02/04 09:11:13 INFO node.AbstractConfigurationProvider: Created channel mem2
18/02/04 09:11:13 INFO channel.DefaultChannelFactory: Creating instance of channel mem1 type memory
18/02/04 09:11:13 INFO node.AbstractConfigurationProvider: Created channel mem1
18/02/04 09:11:13 INFO sink.DefaultSinkFactory: Creating instance of sink: std1, type: hdfs
18/02/04 09:11:14 INFO hdfs.HDFSEventSink: Hadoop Security enabled: false
18/02/04 09:11:14 INFO sink.DefaultSinkFactory: Creating instance of sink: std2, type: hdfs
18/02/04 09:11:14 ERROR node.AbstractConfigurationProvider: Sink std2 has been removed due to an error during configuration
java.lang.NullPointerException: hdfs.path is required




Step 7: open hue and check the data is available in hive table  or not.
Step8: Stop flume service by  pressing ctrl+c
